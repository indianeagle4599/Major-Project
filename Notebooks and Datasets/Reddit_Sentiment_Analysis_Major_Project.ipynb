{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis using NLP on Reddit Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "\n",
    "import nltk \n",
    "import string\n",
    "import re\n",
    "import unicodedata\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB, BernoulliNB\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "import pickle\n",
    "import winsound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alertme(times, diff):\n",
    "    frequency = 2500  # Set Frequency To 2500 Hertz\n",
    "    duration = 500  # Set Duration To 1000 ms == 1 second\n",
    "    for i in range(times*diff):\n",
    "        if i % diff == 0:\n",
    "            winsound.Beep(frequency, duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need this function because model training can take extremely long"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>family mormon have never tried explain them t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>buddhism has very much lot compatible with chr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>seriously don say thing first all they won get...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what you have learned yours and only yours wha...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>for your own benefit you may want read living ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37244</th>\n",
       "      <td>jesus</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37245</th>\n",
       "      <td>kya bhai pure saal chutiya banaya modi aur jab...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37246</th>\n",
       "      <td>downvote karna tha par upvote hogaya</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37247</th>\n",
       "      <td>haha nice</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37248</th>\n",
       "      <td>facebook itself now working bjpâ cell</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37249 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  Sentiment\n",
       "0       family mormon have never tried explain them t...          1\n",
       "1      buddhism has very much lot compatible with chr...          1\n",
       "2      seriously don say thing first all they won get...         -1\n",
       "3      what you have learned yours and only yours wha...          0\n",
       "4      for your own benefit you may want read living ...          1\n",
       "...                                                  ...        ...\n",
       "37244                                              jesus          0\n",
       "37245  kya bhai pure saal chutiya banaya modi aur jab...          1\n",
       "37246              downvote karna tha par upvote hogaya           0\n",
       "37247                                         haha nice           1\n",
       "37248           facebook itself now working bjpâ cell           0\n",
       "\n",
       "[37249 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./Data/Reddit_data.csv', encoding='latin1', names=['text', 'Sentiment'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text         100\n",
       "Sentiment      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text         0\n",
       "Sentiment    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.fillna(-2)\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>family mormon have never tried explain them t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>buddhism has very much lot compatible with chr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>seriously don say thing first all they won get...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what you have learned yours and only yours wha...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>for your own benefit you may want read living ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37144</th>\n",
       "      <td>jesus</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37145</th>\n",
       "      <td>kya bhai pure saal chutiya banaya modi aur jab...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37146</th>\n",
       "      <td>downvote karna tha par upvote hogaya</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37147</th>\n",
       "      <td>haha nice</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37148</th>\n",
       "      <td>facebook itself now working bjpâ cell</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37149 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  Sentiment\n",
       "0       family mormon have never tried explain them t...          1\n",
       "1      buddhism has very much lot compatible with chr...          1\n",
       "2      seriously don say thing first all they won get...         -1\n",
       "3      what you have learned yours and only yours wha...          0\n",
       "4      for your own benefit you may want read living ...          1\n",
       "...                                                  ...        ...\n",
       "37144                                              jesus          0\n",
       "37145  kya bhai pure saal chutiya banaya modi aur jab...          1\n",
       "37146              downvote karna tha par upvote hogaya           0\n",
       "37147                                         haha nice           1\n",
       "37148           facebook itself now working bjpâ cell           0\n",
       "\n",
       "[37149 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = []\n",
    "Sentiment = []\n",
    "\n",
    "for i in range(len(df['text'])):\n",
    "    if df['text'][i] != -2 and df['Sentiment'][i] != -2:\n",
    "        text.append(df['text'][i])\n",
    "        Sentiment.append(df['Sentiment'][i])\n",
    "\n",
    "df2 = pd.DataFrame([])\n",
    "df2['text'] = text\n",
    "df2['Sentiment'] = Sentiment\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1, -1,  0], dtype=int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df2\n",
    "df['Sentiment'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>family mormon have never tried explain them t...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>buddhism has very much lot compatible with chr...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>seriously don say thing first all they won get...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what you have learned yours and only yours wha...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>for your own benefit you may want read living ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37144</th>\n",
       "      <td>jesus</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37145</th>\n",
       "      <td>kya bhai pure saal chutiya banaya modi aur jab...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37146</th>\n",
       "      <td>downvote karna tha par upvote hogaya</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37147</th>\n",
       "      <td>haha nice</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37148</th>\n",
       "      <td>facebook itself now working bjpâ cell</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37149 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text Sentiment\n",
       "0       family mormon have never tried explain them t...  Positive\n",
       "1      buddhism has very much lot compatible with chr...  Positive\n",
       "2      seriously don say thing first all they won get...  Negative\n",
       "3      what you have learned yours and only yours wha...   Neutral\n",
       "4      for your own benefit you may want read living ...  Positive\n",
       "...                                                  ...       ...\n",
       "37144                                              jesus   Neutral\n",
       "37145  kya bhai pure saal chutiya banaya modi aur jab...  Positive\n",
       "37146              downvote karna tha par upvote hogaya    Neutral\n",
       "37147                                         haha nice   Positive\n",
       "37148           facebook itself now working bjpâ cell    Neutral\n",
       "\n",
       "[37149 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = []\n",
    "\n",
    "for i in range(len(df['Sentiment'])):\n",
    "    if df['Sentiment'][i] == -1:\n",
    "        y.append('Negative')\n",
    "    elif df['Sentiment'][i] == 0:\n",
    "        y.append('Neutral')\n",
    "    elif df['Sentiment'][i] == 1:\n",
    "        y.append('Positive')\n",
    "        \n",
    "df['Sentiment'] = y\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopword = nltk.corpus.stopwords.words('english')\n",
    "wn = nltk.WordNetLemmatizer()\n",
    "ps = nltk.PorterStemmer()\n",
    "            \n",
    "def strip_accents(text):\n",
    "    try:\n",
    "        text = unicode(text, 'utf-8')\n",
    "    except NameError: # unicode is a default on python 3 \n",
    "        pass\n",
    "\n",
    "    text = unicodedata.normalize('NFD', text)\\\n",
    "           .encode('ascii', 'ignore')\\\n",
    "           .decode(\"utf-8\")\n",
    "    return str(text)\n",
    "\n",
    "def clean_up_sentence(text):\n",
    "    \n",
    "    # Shift to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Removing mentions, hashtags and urls\n",
    "    for i in range(len(text)):\n",
    "        if text[i] == '#' or text[i] == '@':\n",
    "            j = 0\n",
    "            maxj = len(text)-i\n",
    "            while(j <maxj and text[i+j] != ' '):\n",
    "                if i+j < len(text):\n",
    "                    text = text[0:i+j] + '.' + text[i+j+1:]\n",
    "                    j += 1\n",
    "        elif text[i] == 'h' and i < len(text)-4:\n",
    "            if text[i:i+4] == 'http':\n",
    "                j = 0\n",
    "                maxj = len(text)-i\n",
    "                while(j <maxj and text[i+j] != ' '):\n",
    "                    if i+j < len(text):\n",
    "                        text = text[0:i+j] + '#' + text[i+j+1:]\n",
    "                        j += 1\n",
    "    \n",
    "    # Removing Punctuations and numbers\n",
    "    text  = \"\".join([char for char in text if char not in string.punctuation])\n",
    "    text = re.sub('[0-9]+', '', text)\n",
    "    \n",
    "    # Removing unwanted whitespace and removing accents\n",
    "    text = strip_accents(\" \".join(text.split()))\n",
    "    \n",
    "    # Tokenisation\n",
    "    text = re.split('\\W+', text)\n",
    "    if '' in text:\n",
    "        text.remove('')\n",
    "       \n",
    "    # Removing stop words\n",
    "    text = [word for word in text if word not in stopword]\n",
    "    \n",
    "    # Lemmatization\n",
    "    text = [wn.lemmatize(word) for word in text]\n",
    "\n",
    "    # Remove Stopwords\n",
    "    text = [word for word in text if word not in stopword]\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(df['text'], df['Sentiment'], stratify=df['Sentiment'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a pipeline to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Multinomial Naive Bayes\n",
      "\n",
      "[[ 210   16    5]\n",
      " [  71 1055   84]\n",
      " [1788 2190 3869]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.10      0.91      0.18       231\n",
      "     Neutral       0.32      0.87      0.47      1210\n",
      "    Positive       0.98      0.49      0.66      7847\n",
      "\n",
      "    accuracy                           0.55      9288\n",
      "   macro avg       0.47      0.76      0.44      9288\n",
      "weighted avg       0.87      0.55      0.62      9288\n",
      "\n",
      "0.5527562446167097\n",
      "\n",
      "\n",
      "Bernoulli Naive Bayes\n",
      "\n",
      "[[ 397   33   91]\n",
      " [ 922 3061 1626]\n",
      " [ 750  167 2241]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.19      0.76      0.31       521\n",
      "     Neutral       0.94      0.55      0.69      5609\n",
      "    Positive       0.57      0.71      0.63      3158\n",
      "\n",
      "    accuracy                           0.61      9288\n",
      "   macro avg       0.57      0.67      0.54      9288\n",
      "weighted avg       0.77      0.61      0.65      9288\n",
      "\n",
      "0.6135874246339362\n",
      "\n",
      "\n",
      "Stochastic Gradient Descent\n",
      "\n",
      "[[1138   33  148]\n",
      " [ 446 3135  497]\n",
      " [ 485   93 3313]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.55      0.86      0.67      1319\n",
      "     Neutral       0.96      0.77      0.85      4078\n",
      "    Positive       0.84      0.85      0.84      3891\n",
      "\n",
      "    accuracy                           0.82      9288\n",
      "   macro avg       0.78      0.83      0.79      9288\n",
      "weighted avg       0.85      0.82      0.82      9288\n",
      "\n",
      "0.8167527993109388\n",
      "\n",
      "\n",
      "Logistic Regression\n",
      "\n",
      "[[1241   47  186]\n",
      " [ 381 3055  399]\n",
      " [ 447  159 3373]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.60      0.84      0.70      1474\n",
      "     Neutral       0.94      0.80      0.86      3835\n",
      "    Positive       0.85      0.85      0.85      3979\n",
      "\n",
      "    accuracy                           0.83      9288\n",
      "   macro avg       0.80      0.83      0.80      9288\n",
      "weighted avg       0.85      0.83      0.83      9288\n",
      "\n",
      "0.8256890611541774\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = [\n",
    "        MultinomialNB(),\n",
    "        BernoulliNB(),\n",
    "        SGDClassifier(max_iter=10000, n_jobs = 6),\n",
    "        LogisticRegression(max_iter=10000, n_jobs = 6),\n",
    "    ]\n",
    "    \n",
    "model_names = [\n",
    "        '\\nMultinomial Naive Bayes\\n',\n",
    "        '\\nBernoulli Naive Bayes\\n',\n",
    "        '\\nStochastic Gradient Descent\\n',\n",
    "        '\\nLogistic Regression\\n',\n",
    "    ]\n",
    "    \n",
    "for i in range(len(models)):\n",
    "    pl = Pipeline([\n",
    "            ('CV',CountVectorizer(analyzer=clean_up_sentence)),\n",
    "            ('tfidf',TfidfTransformer()),\n",
    "            ('classifier',models[i])\n",
    "        ])\n",
    "        \n",
    "    print(model_names[i])\n",
    "        \n",
    "    pl.fit(x_train,y_train)\n",
    "    prd = pl.predict(x_test)\n",
    "        \n",
    "    print(confusion_matrix(prd,y_test), end='\\n\\n')\n",
    "    print(classification_report(prd,y_test))\n",
    "    print(accuracy_score(prd,y_test))\n",
    "    print()\n",
    "\n",
    "alertme(5,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The best model for this dataset is Logistic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1241   47  186]\n",
      " [ 381 3055  399]\n",
      " [ 447  159 3373]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.60      0.84      0.70      1474\n",
      "     Neutral       0.94      0.80      0.86      3835\n",
      "    Positive       0.85      0.85      0.85      3979\n",
      "\n",
      "    accuracy                           0.83      9288\n",
      "   macro avg       0.80      0.83      0.80      9288\n",
      "weighted avg       0.85      0.83      0.83      9288\n",
      "\n",
      "0.8256890611541774\n",
      "\n"
     ]
    }
   ],
   "source": [
    "finalPipe = Pipeline([\n",
    "            ('CV',CountVectorizer(analyzer=clean_up_sentence)),\n",
    "            ('tfidf',TfidfTransformer()),\n",
    "            ('classifier',LogisticRegression(max_iter=10000))\n",
    "        ])\n",
    "        \n",
    "finalPipe.fit(x_train,y_train)\n",
    "prd = finalPipe.predict(x_test)\n",
    "        \n",
    "print(confusion_matrix(prd,y_test), end='\\n\\n')\n",
    "print(classification_report(prd,y_test))\n",
    "print(accuracy_score(prd,y_test))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'Major_Project_Reddit.sav'\n",
    "pickle.dump(finalPipe, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we have created the Final Pipeline which should be saved. It contains the model with the highest accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
