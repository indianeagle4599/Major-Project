{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis using NLP on Indian Tweets Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "\n",
    "import nltk \n",
    "import string\n",
    "import re\n",
    "import unicodedata\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB, BernoulliNB\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "import pickle\n",
    "import winsound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alertme(times, diff):\n",
    "    frequency = 2500  # Set Frequency To 2500 Hertz\n",
    "    duration = 500  # Set Duration To 1000 ms == 1 second\n",
    "    for i in range(times*diff):\n",
    "        if i % diff == 0:\n",
    "            winsound.Beep(frequency, duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>when modi promised âminimum government maxim...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>talk all the nonsense and continue all the dra...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what did just say vote for modi  welcome bjp t...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>asking his supporters prefix chowkidar their n...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>answer who among these the most powerful world...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162974</th>\n",
       "      <td>why these 456 crores paid neerav modi not reco...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162975</th>\n",
       "      <td>dear rss terrorist payal gawar what about modi...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162976</th>\n",
       "      <td>did you cover her interaction forum where she ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162977</th>\n",
       "      <td>there big project came into india modi dream p...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162978</th>\n",
       "      <td>have you ever listen about like gurukul where ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>162979 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  Sentiment\n",
       "0       when modi promised âminimum government maxim...       -1.0\n",
       "1       talk all the nonsense and continue all the dra...        0.0\n",
       "2       what did just say vote for modi  welcome bjp t...        1.0\n",
       "3       asking his supporters prefix chowkidar their n...        1.0\n",
       "4       answer who among these the most powerful world...        1.0\n",
       "...                                                   ...        ...\n",
       "162974  why these 456 crores paid neerav modi not reco...       -1.0\n",
       "162975  dear rss terrorist payal gawar what about modi...       -1.0\n",
       "162976  did you cover her interaction forum where she ...        0.0\n",
       "162977  there big project came into india modi dream p...        0.0\n",
       "162978  have you ever listen about like gurukul where ...        1.0\n",
       "\n",
       "[162979 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./Data/Twitter_data.csv', encoding='latin1', names=['text', 'Sentiment'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text         3\n",
       "Sentiment    7\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text         0\n",
       "Sentiment    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.fillna(-2)\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>when modi promised âminimum government maxim...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>talk all the nonsense and continue all the dra...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what did just say vote for modi  welcome bjp t...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>asking his supporters prefix chowkidar their n...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>answer who among these the most powerful world...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162964</th>\n",
       "      <td>why these 456 crores paid neerav modi not reco...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162965</th>\n",
       "      <td>dear rss terrorist payal gawar what about modi...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162966</th>\n",
       "      <td>did you cover her interaction forum where she ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162967</th>\n",
       "      <td>there big project came into india modi dream p...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162968</th>\n",
       "      <td>have you ever listen about like gurukul where ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>162969 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  Sentiment\n",
       "0       when modi promised âminimum government maxim...       -1.0\n",
       "1       talk all the nonsense and continue all the dra...        0.0\n",
       "2       what did just say vote for modi  welcome bjp t...        1.0\n",
       "3       asking his supporters prefix chowkidar their n...        1.0\n",
       "4       answer who among these the most powerful world...        1.0\n",
       "...                                                   ...        ...\n",
       "162964  why these 456 crores paid neerav modi not reco...       -1.0\n",
       "162965  dear rss terrorist payal gawar what about modi...       -1.0\n",
       "162966  did you cover her interaction forum where she ...        0.0\n",
       "162967  there big project came into india modi dream p...        0.0\n",
       "162968  have you ever listen about like gurukul where ...        1.0\n",
       "\n",
       "[162969 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = []\n",
    "Sentiment = []\n",
    "\n",
    "for i in range(len(df['text'])):\n",
    "    if df['text'][i] != -2 and df['Sentiment'][i] != -2:\n",
    "        text.append(df['text'][i])\n",
    "        Sentiment.append(df['Sentiment'][i])\n",
    "\n",
    "df2 = pd.DataFrame([])\n",
    "df2['text'] = text\n",
    "df2['Sentiment'] = Sentiment\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.,  0.,  1.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df2\n",
    "df['Sentiment'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>when modi promised âminimum government maxim...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>talk all the nonsense and continue all the dra...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what did just say vote for modi  welcome bjp t...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>asking his supporters prefix chowkidar their n...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>answer who among these the most powerful world...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162964</th>\n",
       "      <td>why these 456 crores paid neerav modi not reco...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162965</th>\n",
       "      <td>dear rss terrorist payal gawar what about modi...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162966</th>\n",
       "      <td>did you cover her interaction forum where she ...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162967</th>\n",
       "      <td>there big project came into india modi dream p...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162968</th>\n",
       "      <td>have you ever listen about like gurukul where ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>162969 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text Sentiment\n",
       "0       when modi promised âminimum government maxim...  Negative\n",
       "1       talk all the nonsense and continue all the dra...   Neutral\n",
       "2       what did just say vote for modi  welcome bjp t...  Positive\n",
       "3       asking his supporters prefix chowkidar their n...  Positive\n",
       "4       answer who among these the most powerful world...  Positive\n",
       "...                                                   ...       ...\n",
       "162964  why these 456 crores paid neerav modi not reco...  Negative\n",
       "162965  dear rss terrorist payal gawar what about modi...  Negative\n",
       "162966  did you cover her interaction forum where she ...   Neutral\n",
       "162967  there big project came into india modi dream p...   Neutral\n",
       "162968  have you ever listen about like gurukul where ...  Positive\n",
       "\n",
       "[162969 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = []\n",
    "\n",
    "for i in range(len(df['Sentiment'])):\n",
    "    if df['Sentiment'][i] == -1:\n",
    "        y.append('Negative')\n",
    "    elif df['Sentiment'][i] == 0:\n",
    "        y.append('Neutral')\n",
    "    elif df['Sentiment'][i] == 1:\n",
    "        y.append('Positive')\n",
    "        \n",
    "df['Sentiment'] = y\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopword = nltk.corpus.stopwords.words('english')\n",
    "wn = nltk.WordNetLemmatizer()\n",
    "ps = nltk.PorterStemmer()\n",
    "            \n",
    "def strip_accents(text):\n",
    "    try:\n",
    "        text = unicode(text, 'utf-8')\n",
    "    except NameError: # unicode is a default on python 3 \n",
    "        pass\n",
    "\n",
    "    text = unicodedata.normalize('NFD', text)\\\n",
    "           .encode('ascii', 'ignore')\\\n",
    "           .decode(\"utf-8\")\n",
    "    return str(text)\n",
    "\n",
    "def clean_up_sentence(text):\n",
    "    \n",
    "    # Shift to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Removing mentions, hashtags and urls\n",
    "    for i in range(len(text)):\n",
    "        if text[i] == '#' or text[i] == '@':\n",
    "            j = 0\n",
    "            maxj = len(text)-i\n",
    "            while(j <maxj and text[i+j] != ' '):\n",
    "                if i+j < len(text):\n",
    "                    text = text[0:i+j] + '.' + text[i+j+1:]\n",
    "                    j += 1\n",
    "        elif text[i] == 'h' and i < len(text)-4:\n",
    "            if text[i:i+4] == 'http':\n",
    "                j = 0\n",
    "                maxj = len(text)-i\n",
    "                while(j <maxj and text[i+j] != ' '):\n",
    "                    if i+j < len(text):\n",
    "                        text = text[0:i+j] + '#' + text[i+j+1:]\n",
    "                        j += 1\n",
    "    \n",
    "    # Removing Punctuations and numbers\n",
    "    text  = \"\".join([char for char in text if char not in string.punctuation])\n",
    "    text = re.sub('[0-9]+', '', text)\n",
    "    \n",
    "    # Removing unwanted whitespace and removing accents\n",
    "    text = strip_accents(\" \".join(text.split()))\n",
    "    \n",
    "    # Tokenisation\n",
    "    text = re.split('\\W+', text)\n",
    "    if '' in text:\n",
    "        text.remove('')\n",
    "       \n",
    "    # Removing stop words\n",
    "    text = [word for word in text if word not in stopword]\n",
    "    \n",
    "    # Lemmatization\n",
    "    text = [wn.lemmatize(word) for word in text]\n",
    "\n",
    "    # Remove Stopwords\n",
    "    text = [word for word in text if word not in stopword]\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df['text']\n",
    "y = df['Sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, stratify = y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a pipeline to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Multinomial Naive Bayes\n",
      "\n",
      "[[ 1209    46    36]\n",
      " [  407  5548   386]\n",
      " [ 9037 10969 21253]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.11      0.94      0.20      1291\n",
      "     Neutral       0.33      0.87      0.48      6341\n",
      "    Positive       0.98      0.52      0.68     41259\n",
      "\n",
      "    accuracy                           0.57     48891\n",
      "   macro avg       0.48      0.78      0.45     48891\n",
      "weighted avg       0.87      0.57      0.64     48891\n",
      "\n",
      "0.5729070790124972\n",
      "\n",
      "\n",
      "Bernoulli Naive Bayes\n",
      "\n",
      "[[ 4663   596  1200]\n",
      " [ 1781 13734  1951]\n",
      " [ 4209  2233 18524]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.44      0.72      0.54      6459\n",
      "     Neutral       0.83      0.79      0.81     17466\n",
      "    Positive       0.85      0.74      0.79     24966\n",
      "\n",
      "    accuracy                           0.76     48891\n",
      "   macro avg       0.71      0.75      0.72     48891\n",
      "weighted avg       0.79      0.76      0.77     48891\n",
      "\n",
      "0.7551696631281831\n",
      "\n",
      "\n",
      "Stochastic Gradient Descent\n",
      "\n",
      "[[ 6511   199   746]\n",
      " [ 2340 15947  2785]\n",
      " [ 1802   417 18144]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.61      0.87      0.72      7456\n",
      "     Neutral       0.96      0.76      0.85     21072\n",
      "    Positive       0.84      0.89      0.86     20363\n",
      "\n",
      "    accuracy                           0.83     48891\n",
      "   macro avg       0.80      0.84      0.81     48891\n",
      "weighted avg       0.86      0.83      0.83     48891\n",
      "\n",
      "0.8304595937902681\n",
      "\n",
      "\n",
      "Logistic Regression\n",
      "\n",
      "[[ 7910   283   879]\n",
      " [ 1314 15824  1618]\n",
      " [ 1429   456 19178]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.74      0.87      0.80      9072\n",
      "     Neutral       0.96      0.84      0.90     18756\n",
      "    Positive       0.88      0.91      0.90     21063\n",
      "\n",
      "    accuracy                           0.88     48891\n",
      "   macro avg       0.86      0.88      0.87     48891\n",
      "weighted avg       0.89      0.88      0.88     48891\n",
      "\n",
      "0.8777075535374609\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = [\n",
    "        MultinomialNB(),\n",
    "        BernoulliNB(),\n",
    "        SGDClassifier(max_iter=10000, n_jobs = 6),\n",
    "        LogisticRegression(max_iter=10000, n_jobs = 6),\n",
    "    ]\n",
    "    \n",
    "model_names = [\n",
    "        '\\nMultinomial Naive Bayes\\n',\n",
    "        '\\nBernoulli Naive Bayes\\n',\n",
    "        '\\nStochastic Gradient Descent\\n',\n",
    "        '\\nLogistic Regression\\n',\n",
    "    ]\n",
    "    \n",
    "for i in range(len(models)):\n",
    "    pl = Pipeline([\n",
    "            ('CV',CountVectorizer(analyzer=clean_up_sentence)),\n",
    "            ('tfidf',TfidfTransformer()),\n",
    "            ('classifier',models[i])\n",
    "        ])\n",
    "        \n",
    "    print(model_names[i])\n",
    "        \n",
    "    pl.fit(x_train,y_train)\n",
    "    prd = pl.predict(x_test)\n",
    "        \n",
    "    print(confusion_matrix(prd,y_test), end='\\n\\n')\n",
    "    print(classification_report(prd,y_test))\n",
    "    print(accuracy_score(prd,y_test))\n",
    "    print()\n",
    "\n",
    "alertme(5,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The best model for this dataset is Logistic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 7910   283   879]\n",
      " [ 1314 15824  1618]\n",
      " [ 1429   456 19178]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.74      0.87      0.80      9072\n",
      "     Neutral       0.96      0.84      0.90     18756\n",
      "    Positive       0.88      0.91      0.90     21063\n",
      "\n",
      "    accuracy                           0.88     48891\n",
      "   macro avg       0.86      0.88      0.87     48891\n",
      "weighted avg       0.89      0.88      0.88     48891\n",
      "\n",
      "0.8777075535374609\n",
      "\n"
     ]
    }
   ],
   "source": [
    "finalPipe = Pipeline([\n",
    "            ('CV',CountVectorizer(analyzer=clean_up_sentence)),\n",
    "            ('tfidf',TfidfTransformer()),\n",
    "            ('classifier', LogisticRegression(max_iter=10000))\n",
    "        ])\n",
    "        \n",
    "finalPipe.fit(x_train,y_train)\n",
    "prd = finalPipe.predict(x_test)\n",
    "        \n",
    "print(confusion_matrix(prd,y_test), end='\\n\\n')\n",
    "print(classification_report(prd,y_test))\n",
    "print(accuracy_score(prd,y_test))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'Major_Project_Twitter_India.sav'\n",
    "pickle.dump(finalPipe, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we have created the Final Pipeline which should be saved. It contains the model with the highest accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
