{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"colab":{"name":"Final_Sentiment_Analysis_Major_Project.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"BWcBUy-Z9EOz"},"source":["# Final Implementation of the model"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9-DSi-4aCMgu","executionInfo":{"status":"ok","timestamp":1618314451126,"user_tz":-330,"elapsed":2515,"user":{"displayName":"Hitesh goyal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgS8NxktRkXHwam6jcbsCAbw_TN_He9chunWL8n=s64","userId":"12134315771680824697"}},"outputId":"b0ad44ab-88d3-44f7-e29a-4d0d3f924971"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"PGVVPAR25fle","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618314119566,"user_tz":-330,"elapsed":20856,"user":{"displayName":"Hitesh goyal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgS8NxktRkXHwam6jcbsCAbw_TN_He9chunWL8n=s64","userId":"12134315771680824697"}},"outputId":"b0a6cef8-e35f-4696-b5bc-4026f780f17d"},"source":["!pip install streamlit --quiet\n","!pip install pyngrok==4.1.1 --quiet\n","from pyngrok import ngrok"],"execution_count":2,"outputs":[{"output_type":"stream","text":["\u001b[K     |████████████████████████████████| 8.2MB 3.7MB/s \n","\u001b[K     |████████████████████████████████| 81kB 8.1MB/s \n","\u001b[K     |████████████████████████████████| 4.2MB 50.1MB/s \n","\u001b[K     |████████████████████████████████| 163kB 44.4MB/s \n","\u001b[K     |████████████████████████████████| 112kB 57.4MB/s \n","\u001b[K     |████████████████████████████████| 122kB 38.9MB/s \n","\u001b[K     |████████████████████████████████| 71kB 6.4MB/s \n","\u001b[?25h  Building wheel for blinker (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[31mERROR: google-colab 1.0.0 has requirement ipykernel~=4.10, but you'll have ipykernel 5.5.3 which is incompatible.\u001b[0m\n","  Building wheel for pyngrok (setup.py) ... \u001b[?25l\u001b[?25hdone\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WzA2Fwky5uI1","executionInfo":{"status":"ok","timestamp":1618317558823,"user_tz":-330,"elapsed":1582,"user":{"displayName":"Hitesh goyal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgS8NxktRkXHwam6jcbsCAbw_TN_He9chunWL8n=s64","userId":"12134315771680824697"}},"outputId":"f52e2c0e-0c88-4a7c-f972-5249489dc5e3"},"source":["%%writefile app.py\n","import random\n","import nltk \n","import string\n","import re\n","import unicodedata\n","import pickle\n","\n","nltk.download('stopwords') \n","nltk.download('wordnet') \n","\n","stopword = nltk.corpus.stopwords.words('english')\n","wn = nltk.WordNetLemmatizer()\n","ps = nltk.PorterStemmer()\n","            \n","def strip_accents(text):\n","    try:\n","        text = unicode(text, 'utf-8')\n","    except NameError: # unicode is a default on python 3 \n","        pass\n","\n","    text = unicodedata.normalize('NFD', text)\\\n","           .encode('ascii', 'ignore')\\\n","           .decode(\"utf-8\")\n","    return str(text)\n","\n","def clean_up_sentence(text):\n","    \n","    # Shift to lowercase\n","    text = text.lower()\n","    \n","    # Removing mentions, hashtags and urls\n","    for i in range(len(text)):\n","        if text[i] == '#' or text[i] == '@':\n","            j = 0\n","            maxj = len(text)-i\n","            while(j <maxj and text[i+j] != ' '):\n","                if i+j < len(text):\n","                    text = text[0:i+j] + '.' + text[i+j+1:]\n","                    j += 1\n","        elif text[i] == 'h' and i < len(text)-4:\n","            if text[i:i+4] == 'http':\n","                j = 0\n","                maxj = len(text)-i\n","                while(j <maxj and text[i+j] != ' '):\n","                    if i+j < len(text):\n","                        text = text[0:i+j] + '#' + text[i+j+1:]\n","                        j += 1\n","    \n","    # Removing Punctuations and numbers\n","    text  = \"\".join([char for char in text if char not in string.punctuation])\n","    text = re.sub('[0-9]+', '', text)\n","    \n","    # Removing unwanted whitespace and removing accents\n","    text = strip_accents(\" \".join(text.split()))\n","    \n","    # Tokenisation\n","    text = re.split('\\W+', text)\n","    if '' in text:\n","        text.remove('')\n","       \n","    # Removing stop words\n","    text = [word for word in text if word not in stopword]\n","    \n","    # Lemmatization\n","    text = [wn.lemmatize(word) for word in text]\n","\n","    # Remove Stopwords\n","    text = [word for word in text if word not in stopword]\n","    \n","    return text\n","\n","# Loading all the models\n","reddit = pickle.load(open('/content/drive/MyDrive/Major_Project/Major_Project_Reddit.sav', 'rb'))\n","corona = pickle.load(open('/content/drive/MyDrive/Major_Project/Major_Project_Twitter_Corona.sav', 'rb'))\n","india = pickle.load(open('/content/drive/MyDrive/Major_Project/Major_Project_Twitter_India.sav', 'rb'))\n","mill = pickle.load(open('/content/drive/MyDrive/Major_Project/Major_Project_Twitter_1.6M.sav', 'rb'))\n","comb = pickle.load(open('/content/drive/MyDrive/Major_Project/Major_Project_Twitter_Combined.sav', 'rb'))\n","\n","# Creating list of all models\n","models = [\n","        reddit,\n","        corona,\n","        india,\n","        mill,\n","        comb\n","    ]\n","    \n","# Providing names of all the models\n","model_names = [\n","        'Twitter Reddit',\n","        'Twitter Corona',\n","        'Twitter India',\n","        'Twitter 1.6 M Tweets',\n","        'All data Combined'\n","    ]\n","\n","# Initialising the data needed for the voting\n","# (This data was achieved using the voting and evaluation of the previous models in one of the notebooks)\n","responses = ['Positive', 'Negative', 'Neutral']\n","resNums = [90767, 86082, 7659]\n","fscore = {'Twitter Reddit': {'Positive': 0.4827271811162671,\n","  'Negative': 0.2659666469190279,\n","  'Neutral': 0.11328732303996975},\n"," 'Twitter Corona': {'Positive': 0.579134572809062,\n","  'Negative': 0.4487428698894236,\n","  'Neutral': 0.07083543705486148},\n"," 'Twitter India': {'Positive': 0.5227219671620885,\n","  'Negative': 0.3432644047380044,\n","  'Neutral': 0.12461420441367992},\n"," 'Twitter 1.6 M Tweets': {'Positive': 0.7622099609784753,\n","  'Negative': 0.7457948326904099,\n","  'Neutral': 0},\n"," 'All data Combined': {'Positive': 0.7959466028493437,\n","  'Negative': 0.7776426006018942,\n","  'Neutral': 0.2078676150384671}}\n","\n","def votePredict(ip):\n","\n","  # Empty list to store the predictions of all models\n","  prd = []\n","\n","  # Main predictor loop\n","  for i in range(len(models)):\n","      pl = models[i]\n","      pred = pl.predict([ip])\n","      prd.append(pred)\n","\n","  # The voting system\n","  votes = [0 for res in responses]\n","    \n","  for j in range(len(prd)):\n","      for response in range(len(responses)):\n","          if responses[response] == prd[j]:\n","              votes[response] += fscore[model_names[j]][responses[response]]/resNums[response]**(3/5)\n","  max_index = 0\n","  max_list = []\n","  for vote in range(len(votes)):\n","      if votes[vote] > votes[max_index]:\n","          max_index = vote\n","          max_list = []\n","          max_list = [max_index,]\n","        \n","      elif votes[vote] == votes[max_index]:\n","          max_list.append(vote)\n","    \n","  return responses[random.choice(max_list)]\n","\n","# --------------------------------------------------------------------\n","# Streamlit (Web app) Code\n","import streamlit as st\n","\n","st.title('Classification using Sentiment Analysis')\n","\n","st.write('This application is a simplistic way of suggesting the sentiment of any text. The application is capable of assigning:')\n","st.write('\\t-Positive \\U0001F60A')\n","st.write('\\t-Neutral \\U0001F610')\n","st.write('\\t-Negative \\U0001F614')\n","st.write('to a text provided to it.')\n","st.write('It has been made using ML model trained on data of millions of tweets and thousands of Reddit comments.')\n","st.write('\\n\\nFeel free to try out as many different things as you want. My sentiment towards that is Positive \\U0001F60A')\n","\n","ip = st.text_input('Enter text: ')\n","\n","if len(ip) != 0:\n","  op = votePredict(ip)\n","  if op == 'Neutral':\n","    op += ' \\U0001F610'\n","  elif op == 'Negative':\n","    op += ' \\U0001F614'\n","  elif op == 'Positive':\n","    op += ' \\U0001F60A'\n","  st.title(op)"],"execution_count":27,"outputs":[{"output_type":"stream","text":["Overwriting app.py\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":52},"id":"3ysvy1BS6Y1U","executionInfo":{"status":"ok","timestamp":1618314130404,"user_tz":-330,"elapsed":3219,"user":{"displayName":"Hitesh goyal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgS8NxktRkXHwam6jcbsCAbw_TN_He9chunWL8n=s64","userId":"12134315771680824697"}},"outputId":"ec811e41-3257-46f3-d9fd-b07a86cdebcc"},"source":["!nohup streamlit run app.py &\n","url=ngrok.connect(port='8501')\n","url"],"execution_count":4,"outputs":[{"output_type":"stream","text":["nohup: appending output to 'nohup.out'\n"],"name":"stdout"},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'http://6052d468a995.ngrok.io'"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7mai8a649EPB","executionInfo":{"status":"ok","timestamp":1618320471488,"user_tz":-330,"elapsed":16099,"user":{"displayName":"Hitesh goyal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgS8NxktRkXHwam6jcbsCAbw_TN_He9chunWL8n=s64","userId":"12134315771680824697"}},"outputId":"8d256715-8d9c-4c85-8a74-a49bf7b9787d"},"source":["!python"],"execution_count":28,"outputs":[{"output_type":"stream","text":["Python 3.7.10 (default, Feb 20 2021, 21:17:23) \n","[GCC 7.5.0] on linux\n","Type \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n",">>> \n","KeyboardInterrupt\n",">>> \n","KeyboardInterrupt\n",">>> \n","KeyboardInterrupt\n",">>> ^C\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"dvAbtHTZanas"},"source":[""],"execution_count":null,"outputs":[]}]}