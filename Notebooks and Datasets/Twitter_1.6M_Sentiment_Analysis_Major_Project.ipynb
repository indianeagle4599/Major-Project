{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis using NLP on 1.6 M Tweets Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "\n",
    "import nltk \n",
    "import string\n",
    "import re\n",
    "import unicodedata\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB, BernoulliNB\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "import pickle\n",
    "import winsound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alertme(times, diff):\n",
    "    frequency = 2500  # Set Frequency To 2500 Hertz\n",
    "    duration = 500  # Set Duration To 1000 ms == 1 second\n",
    "    for i in range(times*diff):\n",
    "        if i % diff == 0:\n",
    "            winsound.Beep(frequency, duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need this function because model training can take extremely long"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599995</th>\n",
       "      <td>4</td>\n",
       "      <td>Just woke up. Having no school is the best fee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599996</th>\n",
       "      <td>4</td>\n",
       "      <td>TheWDB.com - Very cool to hear old Walt interv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599997</th>\n",
       "      <td>4</td>\n",
       "      <td>Are you ready for your MoJo Makeover? Ask me f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599998</th>\n",
       "      <td>4</td>\n",
       "      <td>Happy 38th Birthday to my boo of alll time!!! ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599999</th>\n",
       "      <td>4</td>\n",
       "      <td>happy #charitytuesday @theNSPCC @SparksCharity...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1600000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Sentiment                                               text\n",
       "0                0  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
       "1                0  is upset that he can't update his Facebook by ...\n",
       "2                0  @Kenichan I dived many times for the ball. Man...\n",
       "3                0    my whole body feels itchy and like its on fire \n",
       "4                0  @nationwideclass no, it's not behaving at all....\n",
       "...            ...                                                ...\n",
       "1599995          4  Just woke up. Having no school is the best fee...\n",
       "1599996          4  TheWDB.com - Very cool to hear old Walt interv...\n",
       "1599997          4  Are you ready for your MoJo Makeover? Ask me f...\n",
       "1599998          4  Happy 38th Birthday to my boo of alll time!!! ...\n",
       "1599999          4  happy #charitytuesday @theNSPCC @SparksCharity...\n",
       "\n",
       "[1600000 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./Data/1.6 Mill Tweet data.csv', encoding='latin1', names=['Sentiment', 'id', 'date', 'flag', 'user', 'text'])\n",
    "df.drop(columns = ['id', 'date', 'flag', 'user'], inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 4], dtype=int64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Sentiment'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0 represents negative and 4 represents positive. The data is split in a highly polar manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment    0\n",
       "text         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let us replace positive and negative with their respective values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Negative</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Negative</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Negative</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Negative</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Negative</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599995</th>\n",
       "      <td>Positive</td>\n",
       "      <td>Just woke up. Having no school is the best fee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599996</th>\n",
       "      <td>Positive</td>\n",
       "      <td>TheWDB.com - Very cool to hear old Walt interv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599997</th>\n",
       "      <td>Positive</td>\n",
       "      <td>Are you ready for your MoJo Makeover? Ask me f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599998</th>\n",
       "      <td>Positive</td>\n",
       "      <td>Happy 38th Birthday to my boo of alll time!!! ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599999</th>\n",
       "      <td>Positive</td>\n",
       "      <td>happy #charitytuesday @theNSPCC @SparksCharity...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1600000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Sentiment                                               text\n",
       "0        Negative  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
       "1        Negative  is upset that he can't update his Facebook by ...\n",
       "2        Negative  @Kenichan I dived many times for the ball. Man...\n",
       "3        Negative    my whole body feels itchy and like its on fire \n",
       "4        Negative  @nationwideclass no, it's not behaving at all....\n",
       "...           ...                                                ...\n",
       "1599995  Positive  Just woke up. Having no school is the best fee...\n",
       "1599996  Positive  TheWDB.com - Very cool to hear old Walt interv...\n",
       "1599997  Positive  Are you ready for your MoJo Makeover? Ask me f...\n",
       "1599998  Positive  Happy 38th Birthday to my boo of alll time!!! ...\n",
       "1599999  Positive  happy #charitytuesday @theNSPCC @SparksCharity...\n",
       "\n",
       "[1600000 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = []\n",
    "for i in range(len(df['Sentiment'])):\n",
    "    if df['Sentiment'][i] == 0:\n",
    "        y.append('Negative')\n",
    "    elif df['Sentiment'][i] == 4:\n",
    "        y.append('Positive')\n",
    "df['Sentiment'] = y\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopword = nltk.corpus.stopwords.words('english')\n",
    "wn = nltk.WordNetLemmatizer()\n",
    "ps = nltk.PorterStemmer()\n",
    "            \n",
    "def strip_accents(text):\n",
    "    try:\n",
    "        text = unicode(text, 'utf-8')\n",
    "    except NameError: # unicode is a default on python 3 \n",
    "        pass\n",
    "\n",
    "    text = unicodedata.normalize('NFD', text)\\\n",
    "           .encode('ascii', 'ignore')\\\n",
    "           .decode(\"utf-8\")\n",
    "    return str(text)\n",
    "\n",
    "def clean_up_sentence(text):\n",
    "    \n",
    "    # Shift to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Removing mentions, hashtags and urls\n",
    "    for i in range(len(text)):\n",
    "        if text[i] == '#' or text[i] == '@':\n",
    "            j = 0\n",
    "            maxj = len(text)-i\n",
    "            while(j <maxj and text[i+j] != ' '):\n",
    "                if i+j < len(text):\n",
    "                    text = text[0:i+j] + '.' + text[i+j+1:]\n",
    "                    j += 1\n",
    "        elif text[i] == 'h' and i < len(text)-4:\n",
    "            if text[i:i+4] == 'http':\n",
    "                j = 0\n",
    "                maxj = len(text)-i\n",
    "                while(j <maxj and text[i+j] != ' '):\n",
    "                    if i+j < len(text):\n",
    "                        text = text[0:i+j] + '#' + text[i+j+1:]\n",
    "                        j += 1\n",
    "    \n",
    "    # Removing Punctuations and numbers\n",
    "    text  = \"\".join([char for char in text if char not in string.punctuation])\n",
    "    text = re.sub('[0-9]+', '', text)\n",
    "    \n",
    "    # Removing unwanted whitespace and removing accents\n",
    "    text = strip_accents(\" \".join(text.split()))\n",
    "    \n",
    "    # Tokenisation\n",
    "    text = re.split('\\W+', text)\n",
    "    if '' in text:\n",
    "        text.remove('')\n",
    "       \n",
    "    # Removing stop words\n",
    "    text = [word for word in text if word not in stopword]\n",
    "    \n",
    "    # Lemmatization\n",
    "    text = [wn.lemmatize(word) for word in text]\n",
    "\n",
    "    # Remove Stopwords\n",
    "    text = [word for word in text if word not in stopword]\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(df['text'], df['Sentiment'], test_size=0.3 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1120000,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1120000,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a pipeline to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Multinomial Naive Bayes\n",
      "\n",
      "[[187761  61427]\n",
      " [ 51766 179046]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.78      0.75      0.77    249188\n",
      "    Positive       0.74      0.78      0.76    230812\n",
      "\n",
      "    accuracy                           0.76    480000\n",
      "   macro avg       0.76      0.76      0.76    480000\n",
      "weighted avg       0.76      0.76      0.76    480000\n",
      "\n",
      "0.76418125\n",
      "\n",
      "\n",
      "Bernoulli Naive Bayes\n",
      "\n",
      "[[184055  53602]\n",
      " [ 55472 186871]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.77      0.77      0.77    237657\n",
      "    Positive       0.78      0.77      0.77    242343\n",
      "\n",
      "    accuracy                           0.77    480000\n",
      "   macro avg       0.77      0.77      0.77    480000\n",
      "weighted avg       0.77      0.77      0.77    480000\n",
      "\n",
      "0.7727625\n",
      "\n",
      "\n",
      "Stochastic Gradient Descent\n",
      "\n",
      "[[169004  43294]\n",
      " [ 70523 197179]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.71      0.80      0.75    212298\n",
      "    Positive       0.82      0.74      0.78    267702\n",
      "\n",
      "    accuracy                           0.76    480000\n",
      "   macro avg       0.76      0.77      0.76    480000\n",
      "weighted avg       0.77      0.76      0.76    480000\n",
      "\n",
      "0.76288125\n",
      "\n",
      "\n",
      "Logistic Regression\n",
      "\n",
      "[[183546  47750]\n",
      " [ 55981 192723]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.77      0.79      0.78    231296\n",
      "    Positive       0.80      0.77      0.79    248704\n",
      "\n",
      "    accuracy                           0.78    480000\n",
      "   macro avg       0.78      0.78      0.78    480000\n",
      "weighted avg       0.78      0.78      0.78    480000\n",
      "\n",
      "0.78389375\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = [\n",
    "        MultinomialNB(),\n",
    "        BernoulliNB(),\n",
    "        SGDClassifier(max_iter=10000, n_jobs = 6),\n",
    "        LogisticRegression(max_iter=10000, n_jobs = 6),\n",
    "    ]\n",
    "    \n",
    "model_names = [\n",
    "        '\\nMultinomial Naive Bayes\\n',\n",
    "        '\\nBernoulli Naive Bayes\\n',\n",
    "        '\\nStochastic Gradient Descent\\n',\n",
    "        '\\nLogistic Regression\\n',\n",
    "    ]\n",
    "    \n",
    "for i in range(len(models)):\n",
    "    pl = Pipeline([\n",
    "            ('CV',CountVectorizer(analyzer=clean_up_sentence)),\n",
    "            ('tfidf',TfidfTransformer()),\n",
    "            ('classifier',models[i])\n",
    "        ])\n",
    "        \n",
    "    print(model_names[i])\n",
    "        \n",
    "    pl.fit(x_train,y_train)\n",
    "    prd = pl.predict(x_test)\n",
    "        \n",
    "    print(confusion_matrix(prd,y_test), end='\\n\\n')\n",
    "    print(classification_report(prd,y_test))\n",
    "    print(accuracy_score(prd,y_test))\n",
    "    print()\n",
    "\n",
    "alertme(5,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The best model for this dataset is Logistic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[183541  47743]\n",
      " [ 55986 192730]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.77      0.79      0.78    231284\n",
      "    Positive       0.80      0.77      0.79    248716\n",
      "\n",
      "    accuracy                           0.78    480000\n",
      "   macro avg       0.78      0.78      0.78    480000\n",
      "weighted avg       0.78      0.78      0.78    480000\n",
      "\n",
      "0.7838979166666666\n",
      "\n"
     ]
    }
   ],
   "source": [
    "finalPipe = Pipeline([\n",
    "            ('CV',CountVectorizer(analyzer=clean_up_sentence)),\n",
    "            ('tfidf',TfidfTransformer()),\n",
    "            ('classifier',LogisticRegression(max_iter=10000))\n",
    "        ])\n",
    "        \n",
    "finalPipe.fit(x_train,y_train)\n",
    "prd = finalPipe.predict(x_test)\n",
    "        \n",
    "print(confusion_matrix(prd,y_test), end='\\n\\n')\n",
    "print(classification_report(prd,y_test))\n",
    "print(accuracy_score(prd,y_test))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'Major_Project_Twitter_1.6M.sav'\n",
    "pickle.dump(finalPipe, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we have created the Final Pipeline which should be saved. It contains the model with the highest accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
